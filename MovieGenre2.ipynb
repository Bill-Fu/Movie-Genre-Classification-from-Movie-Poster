{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import math\n",
    "import torch, lab_utils, random\n",
    "from torchvision.datasets import CIFAR10 \n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn \n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import json, string\n",
    "import os  \n",
    "import torch.utils.data as data\n",
    "import skimage.transform as pictransform\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import torch.nn.functional as F\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            max_scores, max_labels = outputs.data.max(1)\n",
    "            correct += (max_labels == labels.data).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet, self).__init__()\n",
    "       # Convolutional layers.\n",
    "        self.conv1 = nn.Conv2d(3, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 32, 5)\n",
    "        \n",
    "        # Linear layers.\n",
    "        self.fc1 = nn.Linear(32*42*64, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.conv1(x))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = F.relu(self.conv2(out))\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        # This flattens the output of the previous layer into a vector.\n",
    "        out = out.view(out.size(0), -1) \n",
    "        out = F.relu(self.fc1(out))\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 4 * 7, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, images, labels,imgTransform):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = imgTransform  \n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img, target = self.images[index], self.labels[index]\n",
    "        img=imgTransform(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Genres contains genre's name and its index\n",
    "#Genres_Movies contains movieids for every genre, the index coprresponds to index in Genres\n",
    "Genre_Movies=[]\n",
    "Genres={}\n",
    "my_file=open('input.csv','r')\n",
    "count=0\n",
    "for line in my_file:\n",
    "    ele=line.strip().split(',')\n",
    "    if ele[0] not in Genres:\n",
    "        Genres[ele[0]]=count\n",
    "        count+=1\n",
    "        Genre_Movies.append([])\n",
    "        Genre_Movies[Genres[ele[0]]].append(ele[1])\n",
    "    else:\n",
    "        Genre_Movies[Genres[ele[0]]].append(ele[1])\n",
    "my_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#extract test dataset\n",
    "Test_Movies = []\n",
    "for i in range(len(Genres)):\n",
    "    length = len(Genre_Movies[i])\n",
    "    Test_Movies.append([])\n",
    "    for j in range(int(length/5)):\n",
    "        a = random.sample(Genre_Movies[i],1)\n",
    "        Genre_Movies[i].remove(a[0])\n",
    "        Test_Movies[i].append(a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImgList=[]\n",
    "valImgList=[]\n",
    "trainLabelList=[]\n",
    "valLabelList=[]\n",
    "for index, gen in enumerate(Genres):\n",
    "    if index!=9:\n",
    "        trainLabel=[]\n",
    "        valLabel=[]\n",
    "        trainImg=[]\n",
    "        valImg=[]\n",
    "        #Add image with label 1\n",
    "        for i, mvid in enumerate(Genre_Movies[Genres[gen]]):\n",
    "            if i<5500:\n",
    "                img=Image.open('./posters/'+mvid+'.jpg').convert('RGB')\n",
    "                if i<500:\n",
    "                    valImg.append(img)\n",
    "                    valLabel.append(1)\n",
    "                else:\n",
    "                    trainImg.append(img)\n",
    "                    trainLabel.append(1)\n",
    "            else:\n",
    "                break\n",
    "        if len(trainImg)<5000:\n",
    "            temp=random.sample(Genre_Movies[Genres[gen]],5000-len(trainImg))\n",
    "            for mvid in temp:\n",
    "                img=Image.open('./posters/'+mvid+'.jpg').convert('RGB')\n",
    "                trainImg.append(img)\n",
    "        while(len(trainLabel)<5000): trainLabel.append(1)\n",
    "        #Add image with label 0\n",
    "        label0Img=[]\n",
    "        for i in Genre_Movies:\n",
    "            if i!=Genre_Movies[Genres[gen]]:\n",
    "                for j in i:\n",
    "                    if j not in Genre_Movies[Genres[gen]]:\n",
    "                        label0Img.append(j)\n",
    "        samples=random.sample(label0Img,5500)\n",
    "        for i, mvid in enumerate(samples):\n",
    "            img=Image.open('./posters/'+mvid+'.jpg').convert('RGB')\n",
    "            if i<500:\n",
    "                valImg.append(img)\n",
    "                valLabel.append(0)\n",
    "            else:\n",
    "                trainImg.append(img)\n",
    "                trainLabel.append(0)        \n",
    "        trainImgList.append(trainImg)\n",
    "        valImgList.append(valImg)\n",
    "        trainLabelList.append(trainLabel)\n",
    "        valLabelList.append(valLabel)\n",
    "\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Settings\n",
    "learningRate = 0.03\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "imgTransform = transforms.Compose([transforms.Scale((182,268)),\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.4914, 0.4822, 0.4465), \n",
    "                                                        (0.2023, 0.1994, 0.2010))])\n",
    "\n",
    "#classifier for 9 genres\n",
    "networks=[]\n",
    "for i in range(len(Genres)):\n",
    "    network = LeNet()\n",
    "    optimizer = optim.SGD(network.parameters(), lr = learningRate, momentum=0.85)\n",
    "    mytrainset=MyDataset(trainImgList[i],trainLabelList[i],imgTransform)\n",
    "    myvalset=MyDataset(valImgList[i],valLabelList[i],imgTransform)\n",
    "\n",
    "    mytrainLoader = torch.utils.data.DataLoader(mytrainset, batch_size = 64, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "    myvalLoader = torch.utils.data.DataLoader(myvalset, batch_size = 64, \n",
    "                                        shuffle = False, num_workers = 0)\n",
    "\n",
    "    #train_model(network, criterion, optimizer, mytrainLoader, myvalLoader, n_epochs = 1, use_gpu = False)\n",
    "    networks.append(network)\n",
    "    print \"network %d is done\"%(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Movies_dic = {}\n",
    "Test_dic = {}\n",
    "All_Test = []\n",
    "Label_Vector = []\n",
    "\n",
    "# no repeated test data\n",
    "for i in range(len(Genres)):\n",
    "    All_Test += Test_Movies[i]\n",
    "All_Test = list(set(All_Test))\n",
    "\n",
    "#Test network\n",
    "Test_Sum=0.0\n",
    "Correct_Sum=0.0\n",
    "preprocessFn = transforms.Compose([transforms.ToTensor(), \n",
    "                                   transforms.Normalize(mean = [0.485, 0.456, 0.406], \n",
    "                                                        std=[0.229, 0.224, 0.225])])\n",
    "#each classifier\n",
    "for i in range(len(Genres)):\n",
    "    Test_dic={}\n",
    "    Test_Sum=0.0\n",
    "    Correct_Sum=0.0\n",
    "    for mvid in Test_Movies[i]:\n",
    "        Test_dic[mvid]=1\n",
    "    for index, l in enumerate(Test_Movies):\n",
    "        if index!=i:\n",
    "            for mvid in l: \n",
    "                if mvid not in Test_dic:\n",
    "                    Test_dic[mvid]=0\n",
    "    print len(Test_dic)\n",
    "    networks[i].eval()  \n",
    "    for mvid in All_Test:\n",
    "        image = Image.open('./posters/'+mvid+'.jpg').convert('RGB') \n",
    "        inputVar =  Variable(preprocessFn(image).unsqueeze(0))\n",
    "        Predictions = F.softmax(network(inputVar))\n",
    "        Predictions = Predictions.data\n",
    "        max_score, max_label = Predictions.max(1)\n",
    "        if max_label.numpy()==Test_dic[mvid]:\n",
    "            Correct_Sum+=1\n",
    "        Test_Sum+=1\n",
    "    print \"The accuracy of classifier %d is %f\"%(i,Correct_Sum/Test_Sum)\n",
    "\n",
    "#Actual labels\n",
    "for mvid in All_Test:\n",
    "    for i in range(len(Genres)):\n",
    "        if mvid in Test_Movies[i]:\n",
    "            Label_Vector.append(1)\n",
    "        else:\n",
    "            Label_Vector.append(0)\n",
    "    Movies_dic[mvid] = Label_Vector    \n",
    "\n",
    "#Tested Labels   \n",
    "for mvid in All_Test:\n",
    "    for i in range(len(Genres)):\n",
    "        networks[i].eval()\n",
    "        image = Image.open('./posters/'+mvid+'.jpg').convert('RGB') \n",
    "        inputVar =  Variable(preprocessFn(image).unsqueeze(0))\n",
    "        Predictions = F.softmax(network(inputVar))\n",
    "        Predictions = Predictions.data\n",
    "        max_score, max_label = Predictions.max(1)\n",
    "        if max_label.numpy()==1:\n",
    "            Label_Vector.append(1)\n",
    "        else:\n",
    "            Label_Vector.append(0)\n",
    "    Test_dic[mvid] = label_Vector\n",
    "\n",
    "#Calculate Accuracy\n",
    "acc = 0\n",
    "for mvid in All_Test:\n",
    "    y = Movies_dic[mvid]\n",
    "    b = Test_dic[mvid]\n",
    "    num = 0\n",
    "    denom = 0\n",
    "    for i in range(len(y)):\n",
    "        num = num + (y[i] * b[i])\n",
    "        denom = denom + (y[i] * b[i]) + (y[i] + b[i])%2\n",
    "    acc = acc + math.sqrt(num)/math.sqrt(denom)\n",
    "print acc / len(All_Test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
