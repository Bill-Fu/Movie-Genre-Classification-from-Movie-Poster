{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lab_utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenreClassifier(nn.Module):\n",
    "    def __init__(self, nclass, nlabel):\n",
    "        super(MovieGenreClassifier, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(nclass, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, nlabel),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "def extractObjectFeature(image, id2objects, objectTable):\n",
    "    objdetect = [0] * len(objectTable)\n",
    "    objects = id2objects.get(image, [])\n",
    "    \n",
    "    for obj in objects:\n",
    "        objdetect[objectTable[obj.split(':')[0]]] += float(obj.split(':')[1].strip('%')) / 100\n",
    "        \n",
    "    return objdetect\n",
    "    \n",
    "def extractLabel(image, id2genre, genresTable):\n",
    "    genres = id2genre[image]\n",
    "    genres = genres.split('|')\n",
    "    labelVec = torch.zeros(1, 23)\n",
    "    for genre in genres:\n",
    "        if genre in genresTable:\n",
    "            labelVec[0][genresTable[genre]] = 1\n",
    "    \n",
    "    return labelVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26985/26985 [00:00<00:00, 59596.91it/s]\n",
      "100%|██████████| 1891/1891 [00:00<00:00, 72488.09it/s]\n"
     ]
    }
   ],
   "source": [
    "loader = transforms.Compose([\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, csvfile, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.csvfile = open(csvfile, 'rb')\n",
    "        \n",
    "        reader = csv.reader(self.csvfile)\n",
    "\n",
    "        id2genre = {}\n",
    "        id2objects = {}\n",
    "        for row in reader:\n",
    "            if row[0] != \"\":\n",
    "                id2genre[row[0] + \".jpg\"] = row[4]\n",
    "                id2objects[row[0] + \".jpg\"] = row[6:]\n",
    "        \n",
    "        self.csvfile = open(csvfile, 'rb')\n",
    "        \n",
    "        reader = csv.reader(self.csvfile)\n",
    "        \n",
    "        genres = {}\n",
    "        objects = {}\n",
    "        for row in reader:\n",
    "            genre = row[4].split('|')\n",
    "            for ele in genre:\n",
    "                if ele != '':\n",
    "                    genres[ele] = genres.get(ele, 0) + 1\n",
    "            objs = row[6:]\n",
    "            for obj in objs:\n",
    "                if obj != '':\n",
    "                    objects[obj.split(':')[0]] = objects.get(obj.split(':')[0], 0) + 1\n",
    "\n",
    "        for ele in list(genres):\n",
    "            if (genres[ele] < 100):\n",
    "                del genres[ele]        \n",
    "\n",
    "        genresTable = {}\n",
    "        objectTable = {}\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for ele in list(objects):\n",
    "            objectTable[ele] = count\n",
    "            count += 1\n",
    "        \n",
    "        count = 0\n",
    "        for ele in list(genres):\n",
    "            genresTable[ele] = count\n",
    "            count += 1\n",
    "                \n",
    "        self.dataset = []\n",
    "        self.labels = []\n",
    "            \n",
    "        for img in tqdm(os.listdir(self.root)):\n",
    "            image = extractObjectFeature(img, id2objects, objectTable)\n",
    "            \n",
    "            self.dataset.append(image)\n",
    "            self.labels.append(extractLabel(img, id2genre, genresTable))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = torch.FloatTensor(image)       \n",
    "        \n",
    "        image = image.view(1, -1)\n",
    "        \n",
    "        return image, label\n",
    "                               \n",
    "trainset = MyDataset(root='/home/ubuntu/notebooks/dataset/train',\n",
    "                     csvfile='/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/Dataset/NewMovieGenre.csv')\n",
    "valset = MyDataset(root='/home/ubuntu/notebooks/dataset/validation/',\n",
    "                   csvfile='/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/Dataset/NewMovieGenre.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 211/211 [00:04<00:00, 47.38it/s, accuracy=10.3, loss=0.389]\n",
      "Validation epoch 0: 100%|██████████| 15/15 [00:00<00:00, 71.65it/s, accuracy=10.2, loss=0.273]\n",
      "Training epoch 1: 100%|██████████| 211/211 [00:04<00:00, 51.63it/s, accuracy=12.4, loss=0.262]\n",
      "Validation epoch 1: 100%|██████████| 15/15 [00:00<00:00, 71.00it/s, accuracy=9.17, loss=0.261]\n",
      "Training epoch 2: 100%|██████████| 211/211 [00:04<00:00, 50.56it/s, accuracy=16.8, loss=0.256]\n",
      "Validation epoch 2: 100%|██████████| 15/15 [00:00<00:00, 71.50it/s, accuracy=18.5, loss=0.258]\n",
      "Training epoch 3: 100%|██████████| 211/211 [00:04<00:00, 51.20it/s, accuracy=19.9, loss=0.255]\n",
      "Validation epoch 3: 100%|██████████| 15/15 [00:00<00:00, 70.12it/s, accuracy=20.5, loss=0.258]\n",
      "Training epoch 4: 100%|██████████| 211/211 [00:04<00:00, 50.98it/s, accuracy=20.9, loss=0.253]\n",
      "Validation epoch 4: 100%|██████████| 15/15 [00:00<00:00, 71.65it/s, accuracy=21.1, loss=0.257]\n",
      "Training epoch 5: 100%|██████████| 211/211 [00:04<00:00, 51.53it/s, accuracy=21.2, loss=0.253]\n",
      "Validation epoch 5: 100%|██████████| 15/15 [00:00<00:00, 72.84it/s, accuracy=22, loss=0.256] \n",
      "Training epoch 6: 100%|██████████| 211/211 [00:04<00:00, 52.16it/s, accuracy=21.1, loss=0.252]\n",
      "Validation epoch 6: 100%|██████████| 15/15 [00:00<00:00, 71.52it/s, accuracy=22.6, loss=0.256]\n",
      "Training epoch 7: 100%|██████████| 211/211 [00:04<00:00, 51.22it/s, accuracy=21.3, loss=0.252]\n",
      "Validation epoch 7: 100%|██████████| 15/15 [00:00<00:00, 68.97it/s, accuracy=20.6, loss=0.256]\n",
      "Training epoch 8: 100%|██████████| 211/211 [00:04<00:00, 50.70it/s, accuracy=21.2, loss=0.252]\n",
      "Validation epoch 8: 100%|██████████| 15/15 [00:00<00:00, 67.84it/s, accuracy=20.7, loss=0.256]\n",
      "Training epoch 9: 100%|██████████| 211/211 [00:04<00:00, 51.56it/s, accuracy=21.1, loss=0.252]\n",
      "Validation epoch 9: 100%|██████████| 15/15 [00:00<00:00, 70.88it/s, accuracy=21.1, loss=0.256]\n",
      "Training epoch 10: 100%|██████████| 211/211 [00:04<00:00, 51.91it/s, accuracy=21.4, loss=0.251]\n",
      "Validation epoch 10: 100%|██████████| 15/15 [00:00<00:00, 70.39it/s, accuracy=19.3, loss=0.255]\n",
      "Training epoch 11: 100%|██████████| 211/211 [00:04<00:00, 50.83it/s, accuracy=20.9, loss=0.251]\n",
      "Validation epoch 11: 100%|██████████| 15/15 [00:00<00:00, 66.80it/s, accuracy=21.8, loss=0.256]\n",
      "Training epoch 12: 100%|██████████| 211/211 [00:04<00:00, 50.87it/s, accuracy=21.2, loss=0.251]\n",
      "Validation epoch 12: 100%|██████████| 15/15 [00:00<00:00, 67.11it/s, accuracy=20.8, loss=0.255]\n",
      "Training epoch 13: 100%|██████████| 211/211 [00:04<00:00, 51.05it/s, accuracy=21.2, loss=0.251]\n",
      "Validation epoch 13: 100%|██████████| 15/15 [00:00<00:00, 69.25it/s, accuracy=20.5, loss=0.255]\n",
      "Training epoch 14: 100%|██████████| 211/211 [00:04<00:00, 52.18it/s, accuracy=21.1, loss=0.251]\n",
      "Validation epoch 14: 100%|██████████| 15/15 [00:00<00:00, 70.61it/s, accuracy=20.9, loss=0.255]\n",
      "Training epoch 15: 100%|██████████| 211/211 [00:04<00:00, 50.27it/s, accuracy=21.2, loss=0.251]\n",
      "Validation epoch 15: 100%|██████████| 15/15 [00:00<00:00, 69.33it/s, accuracy=21.9, loss=0.256]\n",
      "Training epoch 16: 100%|██████████| 211/211 [00:04<00:00, 51.03it/s, accuracy=21, loss=0.251]  \n",
      "Validation epoch 16: 100%|██████████| 15/15 [00:00<00:00, 71.02it/s, accuracy=21.1, loss=0.255]\n",
      "Training epoch 17: 100%|██████████| 211/211 [00:04<00:00, 50.63it/s, accuracy=21.1, loss=0.251]\n",
      "Validation epoch 17: 100%|██████████| 15/15 [00:00<00:00, 70.73it/s, accuracy=21.2, loss=0.255]\n",
      "Training epoch 18: 100%|██████████| 211/211 [00:04<00:00, 51.49it/s, accuracy=21.2, loss=0.251]\n",
      "Validation epoch 18: 100%|██████████| 15/15 [00:00<00:00, 70.36it/s, accuracy=20.9, loss=0.255]\n",
      "Training epoch 19: 100%|██████████| 211/211 [00:04<00:00, 51.83it/s, accuracy=21.2, loss=0.251]\n",
      "Validation epoch 19: 100%|██████████| 15/15 [00:00<00:00, 69.36it/s, accuracy=20.6, loss=0.255]\n",
      "/usr/local/lib/python2.7/dist-packages/torch/serialization.py:147: UserWarning: Couldn't retrieve source code for container of type MovieGenreClassifier. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 128, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 128,\n",
    "                                        shuffle = True, num_workers = 0)\n",
    "\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "            \n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            \n",
    "            outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "            \n",
    "            correct += ((labels.data * outlabels).sum(2).sum(1) / (labels.data + outlabels).clamp(0, 1).sum(2).sum(1)).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (inputs, labels)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            inputs = Variable(inputs)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                inputs = inputs.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            \n",
    "            # Forward pass:\n",
    "            outputs = network(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "            \n",
    "            correct += ((labels.data * outlabels).sum(2).sum(1) / (labels.data + outlabels).clamp(0, 1).sum(2).sum(1)).sum()\n",
    "            counter += inputs.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "train = True\n",
    "\n",
    "if train == True:\n",
    "    classifier = MovieGenreClassifier(79, 23)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr = 0.001)\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "    # Train the previously defined model.\n",
    "    train_model(classifier, criterion, optimizer, trainLoader, valLoader, n_epochs = 20, use_gpu = True)\n",
    "    torch.save(classifier, \"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/object_detect.model\")\n",
    "else:\n",
    "    classifier = torch.load(\"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/object_detect.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9654/9654 [00:59<00:00, 163.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Dataset : 27.702679622%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def Evaluation(root, img, classifier, id2objects, objectTable, id2genres, genresTable):\n",
    "    classifier.eval()\n",
    "\n",
    "    feature = extractObjectFeature(img, id2objects, objectTable)\n",
    "    feature = Variable(torch.FloatTensor(feature).view(1, -1).cuda())\n",
    "    \n",
    "    outputs = classifier(feature)\n",
    "    max_scores, max_labels = outputs.data.max(1)\n",
    "    if (max_scores > 0).cpu().numpy():\n",
    "        outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "    else:\n",
    "        outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "        outlabels[0][max_labels] = 1\n",
    "        \n",
    "    if (outlabels.sum(1).sum() > 3):\n",
    "        outlabels[0] = torch.zeros(outlabels[0].size()[0])\n",
    "        outlabels[0][outputs.topk(3)[1][0].data] = 1\n",
    "    \n",
    "    labels = extractLabel(img, id2genres, genresTable).cuda()\n",
    "    \n",
    "    correct = ((labels * outlabels).sum(1) / (labels + outlabels).clamp(0, 1).sum(1)).sum()    \n",
    "    \n",
    "    return correct, outlabels, labels\n",
    "\n",
    "csvf = \"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/Dataset/NewMovieGenre.csv\"\n",
    "\n",
    "csvfile = open(csvf, 'rb')\n",
    "\n",
    "reader = csv.reader(csvfile)\n",
    "\n",
    "id2genre = {}\n",
    "id2objects = {}\n",
    "for row in reader:\n",
    "    if row[0] != \"\":\n",
    "        id2genre[row[0] + \".jpg\"] = row[4]\n",
    "        id2objects[row[0] + \".jpg\"] = row[6:]\n",
    "\n",
    "csvfile = open(csvf, 'rb')\n",
    "\n",
    "reader = csv.reader(csvfile)\n",
    "\n",
    "genres = {}\n",
    "objects = {}\n",
    "for row in reader:\n",
    "    genre = row[4].split('|')\n",
    "    for ele in genre:\n",
    "        if ele != '':\n",
    "            genres[ele] = genres.get(ele, 0) + 1\n",
    "    objs = row[6:]\n",
    "    for obj in objs:\n",
    "        if obj != '':\n",
    "            objects[obj.split(':')[0]] = objects.get(obj.split(':')[0], 0) + 1\n",
    "\n",
    "for ele in list(genres):\n",
    "    if (genres[ele] < 100):\n",
    "        del genres[ele]        \n",
    "\n",
    "genresTable = {}\n",
    "objectTable = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "for ele in list(objects):\n",
    "    objectTable[ele] = count\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "for ele in list(genres):\n",
    "    genresTable[ele] = count\n",
    "    count += 1\n",
    "\n",
    "\n",
    "correct = 0\n",
    "\n",
    "for img in tqdm(os.listdir(\"/home/ubuntu/notebooks/dataset/test\")):\n",
    "    correct += Evaluation(\"/home/ubuntu/notebooks/dataset/test\", \n",
    "                          img, \n",
    "                          classifier,\n",
    "                          id2objects,\n",
    "                          objectTable,\n",
    "                          id2genre,\n",
    "                          genresTable)[0]\n",
    "\n",
    "print \"Accuracy on Test Dataset : \" + str(100 * correct / len(os.listdir(\"/home/ubuntu/notebooks/dataset/test\"))) + \"%\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
