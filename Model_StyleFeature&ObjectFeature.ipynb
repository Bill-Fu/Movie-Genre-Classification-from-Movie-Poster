{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import lab_utils\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage import io, transform\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "import csv\n",
    "\n",
    "from tqdm import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Style Feature Extraction Network Based on VGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "dtype = torch.cuda.FloatTensor if use_cuda else torch.FloatTensor\n",
    "\n",
    "cnn = models.vgg19(pretrained=True).features\n",
    "\n",
    "# move it to the GPU if possible:\n",
    "if use_cuda:\n",
    "    cnn = cnn.cuda()\n",
    "    \n",
    "style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "\n",
    "networks = []\n",
    "\n",
    "for i in range(5):\n",
    "    model = nn.Sequential()\n",
    "    networks.append(model)\n",
    "\n",
    "indexs = [1, 3, 6, 8, 11]\n",
    "\n",
    "for n in range(5):\n",
    "    count = 0\n",
    "    for layer in list(cnn)[:indexs[n]]:\n",
    "        networks[n].add_module(str(count), layer)\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Define"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovieGenreClassifier(nn.Module):\n",
    "    def __init__(self, nlabel):\n",
    "        super(MovieGenreClassifier, self).__init__()\n",
    "        self.stylefeature = nn.Sequential(\n",
    "            nn.Linear(64 * 64 + 64 * 64 + 128 * 128 + 128 * 128 + 256 * 256, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 80),\n",
    "        )\n",
    "        self.objectfeature = nn.Sequential(\n",
    "            nn.Linear(79, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 80))\n",
    "        self.allfeature = nn.Sequential(\n",
    "            nn.Linear(160, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 23))\n",
    "\n",
    "    def forward(self, style, obj):\n",
    "        x1 = self.stylefeature(style)\n",
    "        x2 = self.objectfeature(obj)\n",
    "        x = torch.cat((x1, x2), 2)\n",
    "        \n",
    "        return self.allfeature(x)\n",
    "\n",
    "def extractObjectFeature(image, id2objects, objectTable):\n",
    "    objdetect = [0] * len(objectTable)\n",
    "    objects = id2objects.get(image, [])\n",
    "    \n",
    "    for obj in objects:\n",
    "        objdetect[objectTable[obj.split(':')[0]]] += float(obj.split(':')[1].strip('%')) / 100\n",
    "        \n",
    "    return objdetect\n",
    "    \n",
    "def extractStyleFeature(image, networks):\n",
    "    features = []\n",
    "    for network in networks:\n",
    "        features.append(network(image))\n",
    "    for i in range(len(features)):\n",
    "        features[i] = gram(features[i]).view(1, -1)\n",
    "    \n",
    "    return torch.cat((features[0], features[1], features[2], features[3], features[4]), 1)\n",
    "    \n",
    "def extractLabel(image, id2genre, genresTable):\n",
    "    genres = id2genre[image]\n",
    "    genres = genres.split('|')\n",
    "    labelVec = torch.zeros(1, 23)\n",
    "    for genre in genres:\n",
    "        if genre in genresTable:\n",
    "            labelVec[0][genresTable[genre]] = 1\n",
    "    \n",
    "    return labelVec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Gram Matrix to Calculate Style Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = transforms.Compose([\n",
    "    transforms.Scale((182, 268)),\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "def image_loader(image_name):\n",
    "    image = Image.open(image_name)    \n",
    "    image = Variable(loader(image))\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = image.unsqueeze(0)\n",
    "    return image\n",
    "\n",
    "class GramMatrix(nn.Module):\n",
    "    def forward(self, input):\n",
    "        a, b, c, d = input.size()  # a=batch size(=1)\n",
    "        # b=number of feature maps\n",
    "        # (c,d)=dimensions of a f. map (N=c*d)\n",
    "\n",
    "        features = input.view(a * b, c * d)  # resise F_XL into \\hat F_XL\n",
    "\n",
    "        G = torch.mm(features, features.t())  # compute the gram product\n",
    "\n",
    "        # we 'normalize' the values of the gram matrix\n",
    "        # by dividing by the number of element in each feature maps.\n",
    "        return G.div(a * b * c * d)\n",
    "\n",
    "gram = GramMatrix()\n",
    "if use_cuda:\n",
    "    gram = gram.cuda()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26985/26985 [00:31<00:00, 856.98it/s]\n",
      "100%|██████████| 1891/1891 [00:02<00:00, 832.51it/s]\n"
     ]
    }
   ],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, root, csvfile, networks, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.csvfile = open(csvfile, 'rb')\n",
    "        self.networks = networks\n",
    "        \n",
    "        reader = csv.reader(self.csvfile)\n",
    "\n",
    "        id2genre = {}\n",
    "        id2objects = {}\n",
    "        for row in reader:\n",
    "            if row[0] != \"\":\n",
    "                id2genre[row[0] + \".jpg\"] = row[4]\n",
    "                id2objects[row[0] + \".jpg\"] = row[6:]\n",
    "        \n",
    "        self.csvfile = open(csvfile, 'rb')\n",
    "        \n",
    "        reader = csv.reader(self.csvfile)\n",
    "        \n",
    "        genres = {}\n",
    "        objects = {}\n",
    "        for row in reader:\n",
    "            genre = row[4].split('|')\n",
    "            for ele in genre:\n",
    "                if ele != '':\n",
    "                    genres[ele] = genres.get(ele, 0) + 1\n",
    "            objs = row[6:]\n",
    "            for obj in objs:\n",
    "                if obj != '':\n",
    "                    objects[obj.split(':')[0]] = objects.get(obj.split(':')[0], 0) + 1\n",
    "\n",
    "        for ele in list(genres):\n",
    "            if (genres[ele] < 100):\n",
    "                del genres[ele]        \n",
    "\n",
    "        genresTable = {}\n",
    "        objectTable = {}\n",
    "        \n",
    "        count = 0\n",
    "        \n",
    "        for ele in list(objects):\n",
    "            objectTable[ele] = count\n",
    "            count += 1\n",
    "        \n",
    "        count = 0\n",
    "        for ele in list(genres):\n",
    "            genresTable[ele] = count\n",
    "            count += 1\n",
    "                \n",
    "        self.dataset = []\n",
    "        self.objs = []\n",
    "        self.labels = []\n",
    "        \n",
    "        for img in tqdm(os.listdir(self.root)):\n",
    "            image = io.imread(os.path.join(self.root, img))\n",
    "            \n",
    "            obj = extractObjectFeature(img, id2objects, objectTable)\n",
    "            \n",
    "            self.dataset.append(image)\n",
    "            self.objs.append(obj)\n",
    "            self.labels.append(extractLabel(img, id2genre, genresTable))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(os.listdir(self.root))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.dataset[idx]\n",
    "        label = self.labels[idx]\n",
    "        obj = self.objs[idx]\n",
    "        \n",
    "        image = Image.fromarray(image)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        image = Variable(loader(image))\n",
    "        \n",
    "        image = image.cuda()\n",
    "        # fake batch dimension required to fit network's input dimensions\n",
    "        image = image.unsqueeze(0)        \n",
    "        \n",
    "        feature = extractStyleFeature(image, self.networks)\n",
    "        \n",
    "        obj = torch.FloatTensor(obj).view(1, -1)\n",
    "        \n",
    "        return feature.data, obj, label\n",
    "                               \n",
    "trainset = MyDataset(root='/home/ubuntu/notebooks/dataset/train',\n",
    "                     csvfile='/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/Dataset/NewMovieGenre.csv', networks=networks)\n",
    "valset = MyDataset(root='/home/ubuntu/notebooks/dataset/validation/',\n",
    "                   csvfile='/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/Dataset/NewMovieGenre.csv', networks=networks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch 0: 100%|██████████| 422/422 [19:06<00:00,  2.72s/it, accuracy=33.6, loss=0.207]\n",
      "Validation epoch 0: 100%|██████████| 30/30 [01:18<00:00,  2.60s/it, accuracy=30.5, loss=0.229]\n",
      "Training epoch 1: 100%|██████████| 422/422 [19:08<00:00,  2.72s/it, accuracy=33.9, loss=0.207]\n",
      "Validation epoch 1: 100%|██████████| 30/30 [01:18<00:00,  2.60s/it, accuracy=29.7, loss=0.229]\n",
      "Training epoch 2: 100%|██████████| 422/422 [19:06<00:00,  2.72s/it, accuracy=34.1, loss=0.206]\n",
      "Validation epoch 2: 100%|██████████| 30/30 [01:18<00:00,  2.60s/it, accuracy=30.6, loss=0.229]\n",
      "Training epoch 3: 100%|██████████| 422/422 [19:07<00:00,  2.72s/it, accuracy=34.3, loss=0.206]\n",
      "Validation epoch 3: 100%|██████████| 30/30 [01:17<00:00,  2.60s/it, accuracy=30.4, loss=0.228]\n",
      "Training epoch 4: 100%|██████████| 422/422 [19:07<00:00,  2.72s/it, accuracy=34.4, loss=0.205]\n",
      "Validation epoch 4: 100%|██████████| 30/30 [01:18<00:00,  2.61s/it, accuracy=30.7, loss=0.229]\n"
     ]
    }
   ],
   "source": [
    "trainLoader = torch.utils.data.DataLoader(trainset, batch_size = 64, \n",
    "                                          shuffle = True, num_workers = 0)\n",
    "\n",
    "valLoader = torch.utils.data.DataLoader(valset, batch_size = 64,\n",
    "                                        shuffle = True, num_workers = 0)\n",
    "\n",
    "def train_model(network, criterion, optimizer, trainLoader, valLoader, n_epochs = 10, use_gpu = False):\n",
    "    if use_gpu:\n",
    "        network = network.cuda()\n",
    "        criterion = criterion.cuda()\n",
    "        \n",
    "    # Training loop.\n",
    "    for epoch in range(0, n_epochs):\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "\n",
    "        # Make a pass over the training data.\n",
    "        t = tqdm(trainLoader, desc = 'Training epoch %d' % epoch)\n",
    "        network.train()  # This is important to call before training!\n",
    "        for (i, (input1, input2, labels)) in enumerate(t):\n",
    "            \n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            input1 = Variable(input1)\n",
    "            input2 = Variable(input2)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                input1 = input1.cuda()\n",
    "                input2 = input2.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(input1, input2)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass:\n",
    "            optimizer.zero_grad()\n",
    "            # Loss is a variable, and calling backward on a Variable will\n",
    "            # compute all the gradients that lead to that Variable taking on its\n",
    "            # current value.\n",
    "            loss.backward() \n",
    "\n",
    "            # Weight and bias updates.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            \n",
    "            outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "            \n",
    "            correct += ((labels.data * outlabels).sum(2).sum(1) / (labels.data + outlabels).clamp(0, 1).sum(2).sum(1)).sum()\n",
    "            counter += input1.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "        # Make a pass over the validation data.\n",
    "        correct = 0.0\n",
    "        cum_loss = 0.0\n",
    "        counter = 0\n",
    "        t = tqdm(valLoader, desc = 'Validation epoch %d' % epoch)\n",
    "        network.eval()  # This is important to call before evaluating!\n",
    "        for (i, (input1, input2, labels)) in enumerate(t):\n",
    "            # Wrap inputs, and targets into torch.autograd.Variable types.\n",
    "            input1 = Variable(input1)\n",
    "            input2 = Variable(input2)\n",
    "            labels = Variable(labels)\n",
    "            \n",
    "            if use_gpu:\n",
    "                input1 = input1.cuda()\n",
    "                input2 = input2.cuda()\n",
    "                labels = labels.cuda()\n",
    "\n",
    "            # Forward pass:\n",
    "            outputs = network(input1, input2)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # logging information.\n",
    "            cum_loss += loss.data[0]\n",
    "            outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "            \n",
    "            correct += ((labels.data * outlabels).sum(2).sum(1) / (labels.data + outlabels).clamp(0, 1).sum(2).sum(1)).sum()\n",
    "            counter += input1.size(0)\n",
    "            t.set_postfix(loss = cum_loss / (1 + i), accuracy = 100 * correct / counter)\n",
    "\n",
    "train = True\n",
    "\n",
    "if train == True:\n",
    "    classifier = torch.load(\"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/neural_style_and_object_detection05.model\")\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr = 0.0001)\n",
    "    criterion = nn.MultiLabelSoftMarginLoss()\n",
    "    # Train the previously defined model.\n",
    "    train_model(classifier, criterion, optimizer, trainLoader, valLoader, n_epochs = 5, use_gpu = True)\n",
    "    torch.save(classifier, \"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/neural_style_and_object_detection06.model\")\n",
    "else:\n",
    "    classifier = torch.load(\"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/neural_style_and_object_detection05.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9654/9654 [07:30<00:00, 21.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on Test Dataset : 34.5561428444%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def Evaluation(root, img, classifier, networks, id2genre, genresTable, id2objects, objectTable):\n",
    "    classifier.eval()\n",
    "\n",
    "    testImg = io.imread(os.path.join(root, img))\n",
    "    \n",
    "    image = Image.fromarray(testImg)\n",
    "\n",
    "    image = Variable(loader(image))\n",
    "\n",
    "    image = image.cuda()\n",
    "    # fake batch dimension required to fit network's input dimensions\n",
    "    image = image.unsqueeze(0)        \n",
    "\n",
    "    feature = extractStyleFeature(image, networks)\n",
    "    \n",
    "    obj = extractObjectFeature(img, id2objects = id2objects, objectTable = objectTable)\n",
    "    obj = Variable(torch.FloatTensor(obj).view(1, -1)).cuda()\n",
    "    \n",
    "    feature = feature.view(1, 1, -1)\n",
    "    obj = obj.view(1, 1, -1)\n",
    "    \n",
    "    \n",
    "    outputs = classifier(feature, obj)\n",
    "    outputs = outputs.view(1, -1)\n",
    "    max_scores, max_labels = outputs.data.max(1)\n",
    "    if (max_scores > 0).cpu().numpy():\n",
    "        outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "    else:\n",
    "        outlabels = (outputs.data.exp() / (outputs.data.exp() + 1)).round()\n",
    "        outlabels[0][max_labels] = 1\n",
    "        \n",
    "    if (outlabels.sum(1).sum() > 3):\n",
    "        outlabels[0] = torch.zeros(outlabels[0].size()[0])\n",
    "        outlabels[0][outputs.topk(3)[1][0].data] = 1\n",
    "    \n",
    "    labels = extractLabel(img, id2genre, genresTable).cuda()\n",
    "    \n",
    "    correct = ((labels * outlabels).sum(1) / (labels + outlabels).clamp(0, 1).sum(1)).sum()    \n",
    "    \n",
    "    return correct, outlabels, labels\n",
    "\n",
    "csvf = \"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/Dataset/NewMovieGenre.csv\"\n",
    "\n",
    "csvfile = open(csvf, 'rb')\n",
    "\n",
    "reader = csv.reader(csvfile)\n",
    "\n",
    "id2genre = {}\n",
    "id2objects = {}\n",
    "for row in reader:\n",
    "    if row[0] != \"\":\n",
    "        id2genre[row[0] + \".jpg\"] = row[4]\n",
    "        id2objects[row[0] + \".jpg\"] = row[6:]\n",
    "\n",
    "csvfile = open(csvf, 'rb')\n",
    "\n",
    "reader = csv.reader(csvfile)\n",
    "\n",
    "genres = {}\n",
    "objects = {}\n",
    "for row in reader:\n",
    "    genre = row[4].split('|')\n",
    "    for ele in genre:\n",
    "        if ele != '':\n",
    "            genres[ele] = genres.get(ele, 0) + 1\n",
    "    objs = row[6:]\n",
    "    for obj in objs:\n",
    "        if obj != '':\n",
    "            objects[obj.split(':')[0]] = objects.get(obj.split(':')[0], 0) + 1\n",
    "\n",
    "for ele in list(genres):\n",
    "    if (genres[ele] < 100):\n",
    "        del genres[ele]        \n",
    "\n",
    "genresTable = {}\n",
    "objectTable = {}\n",
    "\n",
    "count = 0\n",
    "\n",
    "for ele in list(objects):\n",
    "    objectTable[ele] = count\n",
    "    count += 1\n",
    "\n",
    "count = 0\n",
    "for ele in list(genres):\n",
    "    genresTable[ele] = count\n",
    "    count += 1\n",
    "\n",
    "\n",
    "correct = 0\n",
    "classifier = torch.load(\"/home/ubuntu/notebooks/Movie-Genre-Classification-from-Movie-Poster/neural_style_and_object_detection06.model\")\n",
    "for img in tqdm(os.listdir(\"/home/ubuntu/notebooks/dataset/test\")):\n",
    "    correct += Evaluation(\"/home/ubuntu/notebooks/dataset/test\", \n",
    "                          img, \n",
    "                          classifier, \n",
    "                          networks, \n",
    "                          id2genre,\n",
    "                          genresTable,\n",
    "                          id2objects,\n",
    "                          objectTable)[0]\n",
    "\n",
    "print \"Accuracy on Test Dataset : \" + str(100 * correct / len(os.listdir(\"/home/ubuntu/notebooks/dataset/test\"))) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
